{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read each csv file, preprocess it, then add them to a SQLite as a table.\n",
    "- Historical prices\n",
    "- Options Data\n",
    "- Portfolio holdings\n",
    "- News articles\n",
    "\n",
    "For version1, we have just downloaded historical data downloaded from barchart.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run as is\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# pd.set_option('display.max_rows', 25)\n",
    "pd.set_option('display.max_columns', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def count_files_by_extension(path):\n",
    "    extensions = {}\n",
    "    for file in os.listdir(path):\n",
    "        extension = os.path.splitext(file)[1]\n",
    "        if extension not in extensions:\n",
    "            extensions[extension] = 1\n",
    "        else:\n",
    "            extensions[extension] += 1\n",
    "    return extensions\n",
    "\n",
    "def allfilesinpath(path):\n",
    "    \"\"\"\n",
    "    Get all files in a directory specified by the path.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path of the directory.\n",
    "\n",
    "    Returns:\n",
    "        A list of all files in the directory.\n",
    "    \"\"\"\n",
    "    # Create a list of all files in the specified path\n",
    "    all_files = glob.glob(path + \"/*\")\n",
    "  \n",
    "    return all_files\n",
    "\n",
    "# This function gets all the files in the path, and separates them by substrings\n",
    "def separate_files_by_substrings_in_path(path, substr_list):\n",
    "    # Creates a list of all files in the path\n",
    "    file_paths = glob.glob(path + \"/*\")\n",
    "\n",
    "    # Extract the file names and separate them by substrings\n",
    "    file_data = {}\n",
    "    for substr in substr_list:\n",
    "        file_data[substr] = []\n",
    "    for file_path in file_paths:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        for substr in substr_list:\n",
    "            if substr in file_name:\n",
    "                file_data[substr].append(file_name)\n",
    "\n",
    "    return file_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 1, '.csv': 10}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Raw Data/Barchart/'\n",
    "count_files_by_extension(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Raw Data/Barchart/spy_daily_historical-data-04-24-2023.csv',\n",
       " 'Raw Data/Barchart/hyg_daily_historical-data-04-24-2023.csv',\n",
       " 'Raw Data/Barchart/vnq_options-overview-history-04-24-2023.csv',\n",
       " 'Raw Data/Barchart/tlt_daily_historical-data-04-24-2023.csv',\n",
       " 'Raw Data/Barchart/vnq_daily_historical-data-04-24-2023.csv',\n",
       " 'Raw Data/Barchart/vnq_options-overview-history-04-24-2023-2.csv',\n",
       " 'Raw Data/Barchart/vnq_options-overview-history-04-24-2023-3.csv',\n",
       " 'Raw Data/Barchart/lqd_daily_historical-data-04-24-2023.csv',\n",
       " 'Raw Data/Barchart/spy_options-overview-history-04-24-2023 copy.csv',\n",
       " 'Raw Data/Barchart/spy_options-overview-history-04-24-2023-2.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = allfilesinpath(path)\n",
    "file_paths\n",
    "# file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daily': ['spy_daily_historical-data-04-24-2023.csv',\n",
       "  'hyg_daily_historical-data-04-24-2023.csv',\n",
       "  'tlt_daily_historical-data-04-24-2023.csv',\n",
       "  'vnq_daily_historical-data-04-24-2023.csv',\n",
       "  'lqd_daily_historical-data-04-24-2023.csv']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# substrings = ['spy','hyg','vnq','tlt','lqd']\n",
    "substrings = ['daily']\n",
    "names = separate_files_by_substrings_in_path(path,substrings)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the CSV file\n",
    "def readcsv(file):\n",
    "    # parse_dates = ['Time']\n",
    "    df1 = pd.read_csv(file)\n",
    "    # df1 = pd.read_csv(file, parse_dates=parse_dates)\n",
    "\n",
    "    return df1\n",
    "\n",
    "# Function to perform preliminary preprocessing of raw etf data downloaded from Barchart.com\n",
    "def preprocess_historical_etf_data(historical_etf_data):\n",
    "    # Drop last row because it has irrelevant txt\n",
    "    historical_etf_data = historical_etf_data[:-1]\n",
    "    \n",
    "    # rename colomns\n",
    "    historical_etf_data = historical_etf_data.rename(columns={\"Time\": \"date\",\"Change\":\"daily_change\",\"%Chg\":\"perct_chg\"})\n",
    "    \n",
    "    # extract percentage from %Chg string column\n",
    "    historical_etf_data['perct_chg'] = historical_etf_data['perct_chg'].str.replace('%', '').astype(float)\n",
    "\n",
    "    # convert all column headers to lower case\n",
    "    historical_etf_data.columns = historical_etf_data.columns.str.lower()\n",
    "\n",
    "    # convert the date column to a datetime object\n",
    "    historical_etf_data['date'] = pd.to_datetime(historical_etf_data['date'])\n",
    "\n",
    "    return historical_etf_data\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "def write_dataframe_to_sqlite(df, db_file, table_name=None):\n",
    "    '''\n",
    "    Write a pandas dataframe to a new table in a SQLite database.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The dataframe to write to the database.\n",
    "        db_file (str): The name of the SQLite database file.\n",
    "        table_name (str): The name of the table in the database (optional).\n",
    "                          If not specified, the table will be named after the\n",
    "                          dataframe.\n",
    "    '''\n",
    "    # create a connection to the database\n",
    "    conn = sqlite3.connect(db_file)\n",
    "\n",
    "    # if table_name is not specified, use the name of the dataframe\n",
    "    if table_name is None:\n",
    "        table_name = df.name\n",
    "\n",
    "    # write the dataframe to a new table in the database\n",
    "    df.to_sql(name=table_name, con=conn, if_exists='replace', index=False)\n",
    "\n",
    "    # close the database connection\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sqlite_db with out \n",
    "def create_sqlite_db(names):\n",
    "    sqlite_db_name = 'etf_data.db'\n",
    "    # For all etfs\n",
    "    for name in names['daily']:\n",
    "        # Read the file\n",
    "        df = readcsv(path + str(name))\n",
    "        # Do some preperocessing and get the df in our required format\n",
    "        df = preprocess_historical_etf_data(df)\n",
    "        # Write the formatted df as a table to the sqlite db\n",
    "        write_dataframe_to_sqlite(df, sqlite_db_name, str(name[:3]))\n",
    "\n",
    "    return sqlite_db_name\n",
    "\n",
    "def view_table_contents(db_file, table_name):\n",
    "    '''\n",
    "    View the contents of a table in a SQLite database.\n",
    "    \n",
    "    Parameters:\n",
    "        db_file (str): The name of the SQLite database file.\n",
    "        table_name (str): The name of the table to view.\n",
    "    '''\n",
    "    # create a connection to the database\n",
    "    conn = sqlite3.connect(db_file)\n",
    "\n",
    "    # Get the first and last dates for the table\n",
    "    query = f\"SELECT MIN(date), MAX(date) FROM {table_name}\"\n",
    "    date_range = conn.execute(query).fetchone()\n",
    "    print(f\"Date range for {table_name}: {date_range[0]} - {date_range[1]}\\n\")\n",
    "\n",
    "    # read the contents of the table into a pandas dataframe\n",
    "    # df = pd.read_sql_query(f\"SELECT * from {table_name}\", conn)\n",
    "    # print the contents of the dataframe\n",
    "    # print(df)\n",
    "\n",
    "    # close the database connection\n",
    "    conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range for spy: 2000-01-03 00:00:00 - 2023-04-24 00:00:00\n",
      "\n",
      "Date range for tlt: 2002-07-29 00:00:00 - 2023-04-24 00:00:00\n",
      "\n",
      "Date range for hyg: 2007-04-12 00:00:00 - 2023-04-24 00:00:00\n",
      "\n",
      "Date range for lqd: 2002-07-29 00:00:00 - 2023-04-24 00:00:00\n",
      "\n",
      "Date range for vnq: 2004-09-30 00:00:00 - 2023-04-24 00:00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlite_db_name = create_sqlite_db(names)\n",
    "\n",
    "# etf_list is also the tabe name in the sqlite db\n",
    "etf_list = ['spy', 'tlt', 'hyg', 'lqd', 'vnq']\n",
    "for table_name in etf_list:\n",
    "    view_table_contents('etf_data.db', table_name)\n",
    "\n",
    "# We now have a sqlite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2023-04-24\n",
    "2023-04-24\n",
    "2023-04-24"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
